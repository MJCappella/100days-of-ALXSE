{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJCappella/100days-of-ALXSE/blob/main/templates/aistudio_gemini_prompt_freeform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE8UqxrDIez"
      },
      "source": [
        "### Install & import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWIuwKG2_oWE"
      },
      "outputs": [],
      "source": [
        "# Install the client library and import necessary modules.\n",
        "import google.generativeai as genai\n",
        "\n",
        "import base64\n",
        "import copy\n",
        "import hashlib\n",
        "import io\n",
        "import json\n",
        "import mimetypes\n",
        "import pathlib\n",
        "import pprint\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fet3lFjdKHEM"
      },
      "source": [
        "## Set the API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRWILAtCzBE"
      },
      "source": [
        "Add your API_KEY to the secrets manager in the left panel \"üîë\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LaLCwNlkCyQd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "# Configure the client library by providing your API key.\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weo-o73WDpdm"
      },
      "source": [
        "## Parse the arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uIog-0SyDuIF"
      },
      "outputs": [],
      "source": [
        "model = 'gemini-1.5-pro' # @param {isTemplate: true}\n",
        "contents_b64 = 'W10=' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo2NCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RkbnEEIFEHFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8601681d-0a88-4cff-dd17-76214db234bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "gais_contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ca3e641ee9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297606ec-2fbc-487c-9ba6-021e445fd34e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'temperature': 1, 'top_p': 0.95, 'top_k': 64, 'max_output_tokens': 8192}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "11ce12f5bbac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892ee498-baed-49e8-a679-e7a3867bea06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "safety_settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yoL3p3KPylFW"
      },
      "outputs": [],
      "source": [
        "# @title `show_file` function\n",
        "drive = None\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"üìÅ Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o9D5UdhL8MTk"
      },
      "outputs": [],
      "source": [
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F6SKiuo88LQ"
      },
      "source": [
        "## Convert & upload files\n",
        "\n",
        "For each file, Google AI Studio either sent:\n",
        "- a Google Drive IDs\n",
        "- a URL, or\n",
        "- the raw bytes (`inline_data`).\n",
        "\n",
        "The API itself onlty understands two ways of sending files:\n",
        "\n",
        "- `inline_data` - where the bytes are placed inline in the request.\n",
        "- `file_data` - where the file is uploaded to the Files API, and you pass a reference to that file.\n",
        "\n",
        "This section goes through the `contents` from Google AI Studio, and uploads the file data, to the Files API, so Gemini can access it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_wJAs_ZfuwCq"
      },
      "outputs": [],
      "source": [
        "# @title `upload_file` function\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        hash = hashlib.sha256(data).hexdigest()\n",
        "        path = tempfiles / hash\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"üìÅ Files\"in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8TehY-utE3OR"
      },
      "outputs": [],
      "source": [
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUFIM-r39cuc"
      },
      "source": [
        "Here is the coverted `Content`s:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ-sPFRSxdQg"
      },
      "outputs": [],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "d8ecd603-be25-47f6-d646-6e645ffa0400"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "contents must not be empty",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0a3d7faddd4a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgemini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m response = gemini.generate_content(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"contents must not be empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         request = self._prepare_request(\n",
            "\u001b[0;31mTypeError\u001b[0m: contents must not be empty"
          ]
        }
      ],
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Lm3RXwYuGtZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "3ecdb0d1-9247-42b7-98ee-a9f209116886"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-221b36cd2572>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"candidate_count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ],
      "source": [
        "if generation_config.get(\"candidate_count\", 1) == 1:\n",
        "    display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HjT4jtJc2aAk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f42dbf14-86bb-4d2c-cc33-aebe03f5584c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-432c21224387>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ],
      "source": [
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ1YBkS4MV8L"
      },
      "source": [
        "## Or Create a chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOd-4IHUqx4R"
      },
      "outputs": [],
      "source": [
        "gemini = genai.GenerativeModel(\n",
        "    model_name=model,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOPCBs2grsIt"
      },
      "source": [
        "A `ChatSession`, should always end with the model's turn.\n",
        "\n",
        "So before creating the `chat` check whos turn was last.\n",
        "\n",
        "If the user was last, attach all but the last content as the `history` and send the last content with `send_message` to get the model's response.\n",
        "\n",
        "If the model was last, put the whole contents list in the history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIbdDOeFqyiE"
      },
      "outputs": [],
      "source": [
        "model_turn = contents[-1].get(\"role\", None) == \"user\"\n",
        "\n",
        "if model_turn:\n",
        "    chat = gemini.start_chat(history=contents[:-1])\n",
        "\n",
        "    response = chat.send_message(contents[-1])\n",
        "\n",
        "    if generation_config.get(\"candidate_count\", 1) == 1:\n",
        "        display(Markdown(response.text))\n",
        "else:\n",
        "    chat = gemini.start_chat(history=contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gWBb5UtOL5M"
      },
      "outputs": [],
      "source": [
        "if model_turn:\n",
        "    response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdz66HVvsnRc"
      },
      "source": [
        "After that use `send_message` to continue the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb87HPvBrx29"
      },
      "outputs": [],
      "source": [
        "# response = chat.send_message(\"Interesting, tell me more.\")\n",
        "# display(Markdown(response.text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}